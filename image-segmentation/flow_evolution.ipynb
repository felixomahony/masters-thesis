{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import scipy.stats.qmc as qmc\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import random\n",
    "from manim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../out/strokes.pkl', 'rb') as inp:\n",
    "    brushstrokes = pickle.load(inp)\n",
    "with open('../out/U.pkl', 'rb') as inp:\n",
    "    U = np.real(pickle.load(inp))\n",
    "with open('../out/V.pkl', 'rb') as inp:\n",
    "    V = np.real(pickle.load(inp))\n",
    "\n",
    "    \n",
    "sz = np.shape(brushstrokes[0])\n",
    "\n",
    "\n",
    "U = np.random.random(sz)\n",
    "V = np.random.random(sz)\n",
    "\n",
    "im = cv2.imread('../res/starry_night_crop.jpg')\n",
    "im = cv2.colorChange(im, None, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrace(coordinates_x, coordinates_y, velocity_x_prev, velocity_y_prev, dt, aspect_ratio):\n",
    "  velocity_x_prev = np.copy(velocity_x_prev)\n",
    "  velocity_y_prev = np.copy(velocity_y_prev)\n",
    "  nx = np.shape(coordinates_x)[1]\n",
    "  ny = np.shape(coordinates_x)[0]\n",
    "  #First, get the backtraced coordinates (if you follow the streamline\n",
    "  #back, where do we go?)\n",
    "  backtraced_coordinates_x = coordinates_x - dt * velocity_x_prev\n",
    "  backtraced_coordinates_y = coordinates_y - dt * velocity_y_prev\n",
    "\n",
    "  #The reference tells us the matrix index of the matrix we need to select\n",
    "  backtraced_reference_x = backtraced_coordinates_x / aspect_ratio * nx\n",
    "  backtraced_reference_x_low = np.floor(backtraced_reference_x)\n",
    "  backtraced_reference_x_high = np.ceil(backtraced_reference_x)\n",
    "  linear_const_x = backtraced_reference_x - backtraced_reference_x_low\n",
    "  \n",
    "  # backtraced_reference_x_low = np.clip(backtraced_reference_x_low, 0, nx-1)\n",
    "  # backtraced_reference_x_high = np.clip(backtraced_reference_x_high, 0, nx-1)\n",
    "  backtraced_reference_x_low = backtraced_reference_x_low % nx\n",
    "  backtraced_reference_x_high = backtraced_reference_x_high % ny\n",
    "\n",
    "  backtraced_reference_y = backtraced_coordinates_y * ny\n",
    "  backtraced_reference_y_low = np.floor(backtraced_reference_y)\n",
    "  backtraced_reference_y_high = np.ceil(backtraced_reference_y)\n",
    "  linear_const_y = backtraced_reference_y - backtraced_reference_y_low\n",
    "\n",
    "  # backtraced_reference_y_low = np.clip(backtraced_reference_y_low, 0, ny-1)\n",
    "  # backtraced_reference_y_high = np.clip(backtraced_reference_y_high, 0, ny-1)\n",
    "\n",
    "  backtraced_reference_y_low = backtraced_reference_y_low % ny\n",
    "  backtraced_reference_y_high = backtraced_reference_y_high % ny\n",
    "\n",
    "  #Need to reshape the velocity matrix to account for the fact that we can\n",
    "  #only index a vector not a matrix\n",
    "  velocity_x_row = np.reshape(velocity_x_prev,[np.size(velocity_x_prev)])\n",
    "  velocity_y_row = np.reshape(velocity_y_prev,[np.size(velocity_y_prev)])\n",
    "\n",
    "  #Need to amend the referencing to account for the fact it is a vector not\n",
    "  #a matrix.\n",
    "  low_low_index = np.int32((backtraced_reference_x_low)+(backtraced_reference_y_low)*nx)\n",
    "  low_high_index = np.int32((backtraced_reference_x_low)+(backtraced_reference_y_high)*nx)\n",
    "  high_low_index = np.int32((backtraced_reference_x_high)+(backtraced_reference_y_low)*nx)\n",
    "  high_high_index = np.int32((backtraced_reference_x_high)+(backtraced_reference_y_high)*nx)\n",
    "\n",
    "  #Complete interpolation for backtracing\n",
    "  velocity_x = velocity_x_row[low_low_index]* (1-linear_const_x)*(1-linear_const_y) + velocity_x_row[low_high_index]* (1-linear_const_x)*(linear_const_y) + velocity_x_row[high_low_index]* (linear_const_x)*(1-linear_const_y) + velocity_x_row[high_high_index]* (linear_const_x)*(linear_const_y)\n",
    "  velocity_y = velocity_y_row[low_low_index]* (1-linear_const_x)*(1-linear_const_y) + velocity_y_row[low_high_index]* (1-linear_const_x)*(linear_const_y) + velocity_y_row[high_low_index]* (linear_const_x)*(1-linear_const_y) + velocity_y_row[high_high_index]* (linear_const_x)*(linear_const_y)\n",
    "\n",
    "  return (velocity_x, velocity_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mean_velocity(velocity_x, velocity_y):\n",
    "  velocity_x = np.copy(velocity_x)\n",
    "  velocity_y = np.copy(velocity_y)\n",
    "  #Subtract Mean\n",
    "  velocity_x = velocity_x - np.mean(velocity_x)\n",
    "  velocity_y = velocity_y - np.mean(velocity_y)\n",
    "\n",
    "  return (velocity_x, velocity_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuse_incompressible(velocity_x, velocity_y, decay, normalized_wavenumbers_x, normalized_wavenumbers_y):\n",
    "    velocity_x = np.copy(velocity_x)\n",
    "    velocity_y = np.copy(velocity_y)\n",
    "\n",
    "    n_points_y = np.shape(velocity_x)[0]\n",
    "    n_points_x = np.shape(velocity_x)[1]\n",
    "\n",
    "    #Transform Into Fourier\n",
    "    velocity_x_fft = np.fft.fft2(velocity_x)\n",
    "    velocity_y_fft = np.fft.fft2(velocity_y)\n",
    "    \n",
    "    #Low Pass Filter\n",
    "    velocity_x_fft = velocity_x_fft * decay\n",
    "    velocity_y_fft = velocity_y_fft * decay\n",
    "    \n",
    "    #Compute Pseudo Pressure\n",
    "    pressure_fft = velocity_x_fft * normalized_wavenumbers_x + velocity_y_fft * normalized_wavenumbers_y\n",
    "    \n",
    "    #Project Velocities to be Incompressible\n",
    "    velocity_x_fft = velocity_x_fft - pressure_fft * normalized_wavenumbers_x\n",
    "    velocity_y_fft = velocity_y_fft - pressure_fft * normalized_wavenumbers_y\n",
    "    #Transform Into Spatial\n",
    "    velocity_x = np.real(np.fft.ifft2(velocity_x_fft, [n_points_y, n_points_x]));\n",
    "    velocity_y = np.real(np.fft.ifft2(velocity_y_fft, [n_points_y, n_points_x]));\n",
    "\n",
    "    return (velocity_x, velocity_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "nu = 1/50\n",
    "dt = 0.01\n",
    "n_iter = 10000\n",
    "\n",
    "n_points_y = sz[0]\n",
    "n_points_x = sz[1]\n",
    "\n",
    "aspect_ratio = n_points_x/n_points_y\n",
    "coordinates_x = np.ones([n_points_y,1]) @ np.array([np.arange(start = 0, stop = aspect_ratio,step = aspect_ratio/n_points_x)])#linspace(0,aspect_ratio, n_points_x);\n",
    "coordinates_y = np.array([np.arange(0,1,1/n_points_y)]).T * np.ones([1,n_points_x])\n",
    "\n",
    "wavenumbers_1d_x = np.fft.fftfreq(n_points_x)\n",
    "wavenumbers_1d_y = np.fft.fftfreq(n_points_y)\n",
    "#wavenumbers_1d_x = [0:((n_points_x - rem(n_points_x,2))/2-1), -((n_points_x - rem(n_points_x,2))/2):-1];\n",
    "n_fft_points_x = np.shape(wavenumbers_1d_x)[0]\n",
    "#wavenumbers_1d_y = [0:((n_points_y - rem(n_points_y,2))/2-1), -((n_points_y - rem(n_points_y,2))/2):-1];\n",
    "n_fft_points_y = np.shape(wavenumbers_1d_y)[0]\n",
    "\n",
    "wavenumbers_x = np.ones([n_fft_points_y,1]) @ np.array([wavenumbers_1d_x])\n",
    "wavenumbers_y = np.array([wavenumbers_1d_x]).T @ np.ones([1,n_fft_points_x])\n",
    "wavenumbers_x_squared = wavenumbers_x * wavenumbers_x\n",
    "wavenumbers_y_squared = wavenumbers_y * wavenumbers_y\n",
    "wavenumbers_norm = np.sqrt(wavenumbers_x_squared + wavenumbers_y_squared)\n",
    "\n",
    "decay = np.exp(-dt * nu * wavenumbers_norm * wavenumbers_norm)\n",
    "wavenumbers_norm[wavenumbers_norm==0] = 1\n",
    "normalized_wavenumbers_x = wavenumbers_x / wavenumbers_norm\n",
    "normalized_wavenumbers_y = wavenumbers_y / wavenumbers_norm\n",
    "\n",
    "velocity_x = np.zeros([n_points_y, n_points_x])\n",
    "velocity_y = np.zeros([n_points_y, n_points_x])\n",
    "\n",
    "velocity_x_prev = np.zeros([n_points_y, n_points_x])\n",
    "velocity_y_prev = np.zeros([n_points_y, n_points_x])\n",
    "velocity_x_prev = U\n",
    "velocity_x_prev[np.isnan(velocity_x_prev)] = 0\n",
    "velocity_y_prev = V\n",
    "velocity_y_prev[np.isnan(velocity_y_prev)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def curl_fft_UV(U,V):\n",
    "    d_u_d_y_fft = 1j * wavenumbers_y * np.fft.fft2(U)\n",
    "    d_v_d_x_fft = 1j * wavenumbers_x * np.fft.fft2(V)\n",
    "    curl_fft = d_v_d_x_fft - d_u_d_y_fft\n",
    "    return curl_fft\n",
    "def curl_diagram(curl_fft):\n",
    "    # print(curl_fft.shape)\n",
    "    curl = np.fft.ifft2(curl_fft, sz)\n",
    "    curl = np.real(curl)\n",
    "    plt.imshow(curl, cmap = plt.cm.coolwarm)\n",
    "\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "curl_diagram(curl_fft_UV(velocity_x_prev, velocity_y_prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curl_diagram(curl_fft_UV(velocity_x_prev, velocity_y_prev))\n",
    "for iter in range(n_iter):\n",
    "    velocity_x, velocity_y = backtrace(coordinates_x, coordinates_y, velocity_x_prev, velocity_y_prev, dt, aspect_ratio)\n",
    "\n",
    "    velocity_x, velocity_y = zero_mean_velocity(velocity_x, velocity_y)\n",
    "\n",
    "    velocity_x, velocity_y = diffuse_incompressible(velocity_x, velocity_y, decay, normalized_wavenumbers_x, normalized_wavenumbers_y)\n",
    "\n",
    "    velocity_x, velocity_y = zero_mean_velocity(velocity_x, velocity_y)\n",
    "\n",
    "    #Progress in Time\n",
    "    velocity_x_prev = np.copy(velocity_x)\n",
    "    velocity_y_prev = np.copy(velocity_y)\n",
    "    if (iter%100==0):\n",
    "        curl_diagram(curl_fft_UV(velocity_x, velocity_y))\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousMotion(Scene):\n",
    "    def construct(self):\n",
    "        func = lambda pos: np.sin(pos[0] / 2) * UR + np.cos(pos[1] / 2) * LEFT\n",
    "        stream_lines = StreamLines(func, stroke_width=2, max_anchors_per_line=30)\n",
    "        self.add(stream_lines)\n",
    "        stream_lines.start_animation(warm_up=False, flow_speed=1.5)\n",
    "        self.wait(stream_lines.virtual_time / stream_lines.flow_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.max([3,4,-2,4])\n",
    "a += np.min(a)\n",
    "a /= np.max(a)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
